{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dannyljw/new_bicycle/blob/main/%EC%A0%95%EB%A6%AC_%EC%99%84%EB%A3%8C_%EC%BD%94%EB%93%9C%EC%A0%9C%EC%B6%9C_v1_0_220704.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b3aed5",
      "metadata": {
        "id": "b6b3aed5"
      },
      "source": [
        "# feature 추가\n",
        "> 체감온도, 불쾌지수, 네이버 날씨에서 보는 것과 같이 미세먼지 농도에 따른 나쁨/좋음/보통 값 부여, \n",
        "> \n",
        "> rental 되는 자전거 수 비율 적용, date 칼럼을 월/연/일로 나누기\n",
        "> \n",
        "> train/test 데이터에 따라서 각기 다르게 요일 부여"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ee796a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.251819Z",
          "start_time": "2022-07-04T14:19:55.318532Z"
        },
        "id": "72ee796a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from math import ceil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
        "import sklearn\n",
        "from sklearn.preprocessing import *\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "# 체감온도 공식\n",
        "def temp_sensible(df):\n",
        "    #체감온도 공식은 체감온도(℃)=13.12+0.6215×T-11.37V0.16+0.3965V0.16×T\n",
        "    temp_df_t=df['temp_mean'].tolist()\n",
        "    temp_df_w=df['wind_mean'].tolist()\n",
        "    temp_df_t\n",
        "    temp_df_w\n",
        "    result_=[]\n",
        "    for i in range(len(temp_df_t)):\n",
        "        result=13.12+0.6215*temp_df_t[i]-11.37*math.pow(temp_df_w[i],0.16)+0.3965*math.pow(temp_df_w[i],0.16)*temp_df_t[i]\n",
        "        result_.append(round(result,1))\n",
        "    df.insert(4,'temp_sensible',result_)\n",
        "\n",
        "# 불쾌지수 공식\n",
        "def discomfort_index(df):\n",
        "    #0.81 * temp_df_t[i] +0.01 * temp_df_t[i]*((0.99*temp_df_t[i]) - 14.3)+ 46.3\n",
        "    #불쾌지수 공식(80이상 : 매우 불쾌, 80~75: 50%불쾌 , 68~75 :불쾌감 시작, 68미만: 쾌적함)\n",
        "    #discomfort_index(불쾌지수)\n",
        "    temp_df_t=df['temp_mean'].tolist()\n",
        "    temp_df_h=df['humidity'].tolist()\n",
        "    temp_df_t\n",
        "    temp_df_h\n",
        "    result_=[]\n",
        "    for i in range(len(temp_df_t)):\n",
        "        result=(9/5*temp_df_t[i])-0.55*(1-temp_df_h[i]/100)*(9/5*temp_df_t[i]-26)+32\n",
        "        result_.append(round(result,1))\n",
        "    result_\n",
        "    df['discomfort_index']=result_\n",
        "\n",
        "# 미세먼지 PM10, PM2.5 에 따라서 값을 (class) 를 부여\n",
        "def pm_trafficlight(df):\n",
        "    #미세먼지 신호등 \n",
        "    pm10=df['PM10'].tolist()\n",
        "    pm2=df['PM2.5'].tolist()\n",
        "    pm_=[]\n",
        "    for i in range(len(pm10)):\n",
        "        if(pm10[i]<=30 or pm2[i]<=15):\n",
        "            pm_.append(1)\n",
        "        elif((pm10[i]<=80 and pm10[i]>30) or (pm2[i] >=16 and pm2[i]<=50)):\n",
        "            pm_.append(2)\n",
        "        elif((pm10[i]<=150 and pm10[i]>80)or (pm2[i]>50 and pm2[i]<=100)):\n",
        "            pm_.append(3)\n",
        "        elif(pm10[i]>=150 or (pm2[i]>100)):\n",
        "            pm_.append(4)\n",
        "    df['pm']=pm_\n",
        "\n",
        "# 연도별로 rental 값이 전체적으로 상향됨을 확인하여 비율 맞춰줌\n",
        "# 비슷한 맥락으로, 전처리 이후, 예측 prediction 을 진행 한 뒤에 1.35를 곱함\n",
        "def rental_rate(df):\n",
        "    #연도별 증가하는 비율을 조사하고 전체적인 비율을 맞춰주기 위해서 값들을 변환해주었다.--> 추가 설명 필요\n",
        "    y1 = df[df['year'] == 2018]['rental'] * 2.3\n",
        "    y2 = df[df['year'] == 2019]['rental'] * 1.2\n",
        "    y3 = df[df['year'] == 2020]['rental']\n",
        "    new = pd.concat([y1, y2, y3], axis=0).to_frame()\n",
        "    df['rental'] = new['rental']\n",
        "    return True\n",
        "\n",
        "# date 에서 연도 칼럼, 월 칼럼, 일 칼럼 따로 분리 \n",
        "def seperate_date(df):\n",
        "    date=df['date'].tolist()\n",
        "    year=[]\n",
        "    month=[]\n",
        "    day=[]\n",
        "    year_=''\n",
        "    month_=''\n",
        "    day_=''\n",
        "    for j in date:\n",
        "        list_=j.split(\"-\")\n",
        "        for i in range(3):\n",
        "            if(i==0):\n",
        "                year_+=list_[i]\n",
        "            elif(i==1):\n",
        "                month_+=list_[i]\n",
        "            elif(i==2):\n",
        "                day_+=list_[i]\n",
        "        year.append(int(year_))\n",
        "        month.append(int(month_))\n",
        "        day.append(int(day_))\n",
        "        year_=''\n",
        "        month_=''\n",
        "        day_=''\n",
        "    df=df.drop(columns='date')\n",
        "    df['year']=year\n",
        "    df['month']=month\n",
        "    df['day']=day\n",
        "    return df\n",
        "\n",
        "# train 데이터에서 요일 칼럼을 따로 추출하는 작업\n",
        "# test 데이터와 달리 하는 이유는 시작하는 요일이 다르기 때문.\n",
        "def train_day_of_the_week(df):\n",
        "    day = []\n",
        "    for i in range(0,614):\n",
        "        if df.index[i] % 7 == 0:\n",
        "            day.append(\"Monday\")\n",
        "        elif df.index[i] % 7 == 1:\n",
        "            day.append(\"Tuesday\")\n",
        "        elif df.index[i] % 7 ==2:\n",
        "            day.append(\"Wednesday\")\n",
        "        elif df.index[i] % 7 == 3:\n",
        "            day.append(\"Thursday\")\n",
        "        elif df.index[i] % 7 == 4:\n",
        "            day.append(\"Friday\")\n",
        "        elif df.index[i] % 7 == 5:\n",
        "            day.append(\"Saturday\")\n",
        "        elif df.index[i] % 7 == 6:\n",
        "            day.append(\"Sunday\")\n",
        "    for i in range(0,len(df.day)-614):\n",
        "        if df.index[i] % 7 == 0:\n",
        "            day.append(\"Sunday\")\n",
        "        elif df.index[i] % 7 == 1:\n",
        "            day.append(\"Monday\")\n",
        "        elif df.index[i] % 7 == 2:\n",
        "            day.append(\"Tuesday\")\n",
        "        elif df.index[i] % 7 == 3:\n",
        "            day.append(\"Wednesday\")\n",
        "        elif df.index[i] % 7 == 4:\n",
        "            day.append(\"Thursday\")\n",
        "        elif df.index[i] % 7 == 5:\n",
        "            day.append(\"Friday\")\n",
        "        elif df.index[i] % 7 == 6:\n",
        "            day.append(\"Saturday\")\n",
        "    df[\"day_name\"] = day\n",
        "    return df\n",
        "\n",
        "# test 데이터 에서 요일 칼럼을 따로 만드는 함수\n",
        "def test_day_of_the_week(df):\n",
        "    day2= []\n",
        "    for i in range(0,365):\n",
        "        if df.index[i] % 7 == 0:\n",
        "            day2.append(\"Friday\")\n",
        "        elif df.index[i] % 7 == 1:\n",
        "            day2.append(\"Saturday\")\n",
        "        elif df.index[i] % 7 ==2:\n",
        "            day2.append(\"Sunday\")\n",
        "        elif df.index[i] % 7 == 3:\n",
        "            day2.append(\"Monday\")\n",
        "        elif df.index[i] % 7 == 4:\n",
        "            day2.append(\"Tuesday\")\n",
        "        elif df.index[i] % 7 == 5:\n",
        "            day2.append(\"Wednesday\")\n",
        "        elif df.index[i] % 7 == 6:\n",
        "            day2.append(\"Thursday\")\n",
        "    df[\"day_name\"] = day2  \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14070cc9",
      "metadata": {
        "id": "14070cc9"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d72596b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.289840Z",
          "start_time": "2022-07-04T14:19:58.255977Z"
        },
        "id": "7d72596b"
      },
      "outputs": [],
      "source": [
        "sample = pd.read_csv('sample_submission.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ce3173",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.341976Z",
          "start_time": "2022-07-04T14:19:58.293395Z"
        },
        "id": "28ce3173",
        "outputId": "38ef10fa-5f44-4540-87ef-0c2c05492784"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>precipitation</th>\n",
              "      <th>temp_mean</th>\n",
              "      <th>temp_highest</th>\n",
              "      <th>temp_lowest</th>\n",
              "      <th>PM10</th>\n",
              "      <th>PM2.5</th>\n",
              "      <th>humidity</th>\n",
              "      <th>sunshine_sum</th>\n",
              "      <th>sunshine_rate</th>\n",
              "      <th>wind_mean</th>\n",
              "      <th>wind_max</th>\n",
              "      <th>rental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>3.8</td>\n",
              "      <td>-5.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>39.1</td>\n",
              "      <td>8.3</td>\n",
              "      <td>86.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>4950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>36.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>7.9</td>\n",
              "      <td>82.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>4.9</td>\n",
              "      <td>7136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-7.1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>42.3</td>\n",
              "      <td>8.6</td>\n",
              "      <td>88.7</td>\n",
              "      <td>2.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>7156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-8.7</td>\n",
              "      <td>39.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>63.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.5</td>\n",
              "      <td>7102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>-5.6</td>\n",
              "      <td>51.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>48.4</td>\n",
              "      <td>8.2</td>\n",
              "      <td>84.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>3.6</td>\n",
              "      <td>7705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  precipitation  temp_mean  temp_highest  temp_lowest  PM10  \\\n",
              "0  2018-01-01            NaN       -1.3           3.8         -5.1  34.0   \n",
              "1  2018-01-02            NaN       -1.8           1.8         -4.3  36.0   \n",
              "2  2018-01-03            NaN       -4.7          -0.4         -7.1  31.0   \n",
              "3  2018-01-04            NaN       -4.7          -0.7         -8.7  39.0   \n",
              "4  2018-01-05            NaN       -3.0           1.6         -5.6  51.0   \n",
              "\n",
              "   PM2.5  humidity  sunshine_sum  sunshine_rate  wind_mean  wind_max  rental  \n",
              "0   17.0      39.1           8.3           86.5        1.4       3.8    4950  \n",
              "1   22.0      42.0           7.9           82.3        1.8       4.9    7136  \n",
              "2   19.0      42.3           8.6           88.7        2.2       3.5    7156  \n",
              "3   24.0      43.0           6.2           63.9        1.4       3.5    7102  \n",
              "4   35.0      48.4           8.2           84.5        1.7       3.6    7705  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3056903d",
      "metadata": {
        "id": "3056903d"
      },
      "source": [
        "# feature 추가\n",
        "\n",
        "> 2018,2019,2020 년도에 공휴일&주말, 공휴일&평일, 공휴일&월요일, 공휴일&금요일 등 공휴일또한 예측에 영향이 있는 것으로 판단하여 \n",
        ">\n",
        "> 공휴일은 1 부여"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1d8495",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.512112Z",
          "start_time": "2022-07-04T14:19:58.358066Z"
        },
        "id": "9a1d8495"
      },
      "outputs": [],
      "source": [
        "train['holiday']=0\n",
        "train.loc[train['date']=='2018-01-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-02-15', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-02-16', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-02-17', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-03-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-05-05', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-05-07', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-05-22', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-06-06', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-06-13', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-08-15', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-09-23', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-09-24', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-09-25', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-09-26', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-10-03', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-10-09', 'holiday'] =1\n",
        "train.loc[train['date']=='2018-12-25', 'holiday'] =1\n",
        "\n",
        "train.loc[train['date']=='2019-01-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-02-04', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-02-05', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-02-06', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-03-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-05-12', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-06-06', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-08-15', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-09-12', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-09-13', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-09-14', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-10-03', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-10-09', 'holiday'] =1\n",
        "train.loc[train['date']=='2019-12-25', 'holiday'] =1\n",
        "\n",
        "train.loc[train['date']=='2020-01-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-01-24', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-01-25', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-01-26', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-01-27', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-03-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-04-15', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-04-30', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-05-05', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-06-06', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-08-15', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-08-17', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-09-30', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-10-01', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-10-02', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-10-03', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-10-09', 'holiday'] =1\n",
        "train.loc[train['date']=='2020-12-25', 'holiday'] =1\n",
        "\n",
        "\n",
        "test_df.loc[train['date']=='2021-01-01', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-02-11', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-02-12', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-02-13', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-03-01', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-05-05', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-05-19', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-06-06', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-08-15', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-08-16', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-09-20', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-09-21', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-09-22', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-10-03', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-10-04', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-10-09', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-10-11', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-12-25', 'holiday'] =1\n",
        "test_df.loc[train['date']=='2021-12-27', 'holiday'] =1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f029468a",
      "metadata": {
        "id": "f029468a"
      },
      "source": [
        "# train data 함수 적용 & 결측값 처리\n",
        "> 함수 적용 (1)\n",
        ">> \n",
        ">> 위에서 생성한 함수 중 연/월/일 분리하는 함수 적용\n",
        ">\n",
        "> precipitaion, PM10, PM2.5 에 있는 결측값 처리\n",
        ">\n",
        ">> 강수량의 경우 결측값을 0, 미세먼지의 경우 전체(2019~2020) 미세먼지에 대해 평균치로 적용\n",
        "> \n",
        "> 함수 적용 (2)\n",
        ">>\n",
        ">> train 데이터에 요일 부여 ( train_day_of_the_week)\n",
        ">>\n",
        ">> get_dummies 를 통하여 요일 데이터를 one-hot encoding 진행\n",
        "> rental 숫자 자체가 큰 것을 확인하여 Log1p 를 통해 값을 줄여줌 (스케일 시켜줌) -> 나중에 예측 후 expm1 으로 스케일 풀어줌\n",
        ">\n",
        "> 함수 적용 (3)\n",
        ">> 불쾌지수 (discomfort_index), 체감온도 (temp_sensible), 일교차 , 미세먼지 신호등 (미세먼지 지수에 따른 값 부여) 진행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018f1552",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.597837Z",
          "start_time": "2022-07-04T14:19:58.522728Z"
        },
        "id": "018f1552"
      },
      "outputs": [],
      "source": [
        "#결측값 처리-강수량, 미세먼지\n",
        "train_=seperate_date(train)\n",
        "train_['precipitation']=train_['precipitation'].fillna(0)\n",
        "train_['PM10'] = train_['PM10'].fillna(train_['PM10'].mean())\n",
        "train_['PM2.5'] = train_['PM2.5'].fillna(train_['PM2.5'].mean())\n",
        "train_ = train_.fillna(train_.mean())\n",
        "#연도별 rental rate 변화\n",
        "rental_rate(train_)\n",
        "#train 요일 부여\n",
        "train_=train_day_of_the_week(train_)\n",
        "# 요일 one-hot encoding\n",
        "train_= pd.get_dummies(data = train_,columns = ['day_name'])\n",
        "#rental log scaling\n",
        "train_[\"rental\"] = np.log1p(train_[\"rental\"])\n",
        "#불쾌지수\n",
        "discomfort_index(train_)\n",
        "#체감온도\n",
        "temp_sensible(train_)\n",
        "#일교차\n",
        "train_.insert(5,'temp_diff',train_['temp_highest'] - train_['temp_lowest'])\n",
        "#미세먼지 신호등\n",
        "pm_trafficlight(train_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2d6d848",
      "metadata": {
        "id": "c2d6d848"
      },
      "source": [
        "# test data 함수 적용 & 결측값 처리\n",
        "> 함수 적용 (1)\n",
        ">> \n",
        ">> 위에서 생성한 함수 중 연/월/일 분리하는 함수 적용\n",
        ">\n",
        "> precipitaion, PM10, PM2.5 에 있는 결측값 처리\n",
        ">\n",
        ">> 강수량의 경우 결측값을 0, 미세먼지의 경우 전체(2019~2020) 미세먼지에 대해 평균치로 적용\n",
        "> \n",
        "> 함수 적용 (2)\n",
        ">>\n",
        ">> test 데이터에 요일 부여 (test_day_of_the_week)\n",
        ">>\n",
        ">> get_dummies 를 통하여 요일 데이터를 one-hot encoding 진행\n",
        "> rental 숫자 자체가 큰 것을 확인하여 Log1p 를 통해 값을 줄여줌 (스케일 시켜줌) -> 나중에 예측 후 expm1 으로 스케일 풀어줌\n",
        ">\n",
        "> 함수 적용 (3)\n",
        ">> 불쾌지수 (discomfort_index), 체감온도 (temp_sensible), 일교차 , 미세먼지 신호등 (미세먼지 지수에 따른 값 부여) 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db37de5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.670529Z",
          "start_time": "2022-07-04T14:19:58.600670Z"
        },
        "id": "5db37de5"
      },
      "outputs": [],
      "source": [
        "#결측값 처리-강수량, 미세먼지\n",
        "test_date=test_df['date']\n",
        "test_df=seperate_date(test_df)\n",
        "test_df['precipitation']=test_df['precipitation'].fillna(0)\n",
        "test_df['PM10'] = test_df['PM10'].fillna(test_df['PM10'].mean())\n",
        "test_df['PM2.5'] = test_df['PM2.5'].fillna(test_df['PM2.5'].mean())\n",
        "#연도별 rental rate 변화\n",
        "test_df=test_df.fillna(test_df.mean())\n",
        "#train 요일 부여\n",
        "test_df=test_day_of_the_week(test_df)\n",
        "# 요일 one-hot encoding\n",
        "test_df = pd.get_dummies(data = test_df,columns = [\"day_name\"])\n",
        "#rental log scaling\n",
        "discomfort_index(test_df)\n",
        "#불쾌지수\n",
        "temp_sensible(test_df)\n",
        "#일교차\n",
        "test_df.insert(5,'temp_diff',train_['temp_highest'] - train_['temp_lowest'])\n",
        "#미세먼지 신호등\n",
        "pm_trafficlight(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc50cfa9",
      "metadata": {
        "id": "bc50cfa9"
      },
      "source": [
        "# 데이터 Scaling\n",
        "> MinMax, Stadardization, Normalization, QuantileTransformer 등 다양한 scaling 기법을 사용하였으나, \n",
        "> QuantileTransformer() 가 제일 데이터 scaling 후 표현을 잘하여 선정\n",
        ">> 'PM10','PM2.5','sunshine_rate','sunshine_sum', 'precipitation' 의 경우 데이터를 시각화 하였을때, (x축->rental y축->앞에 표시) 제일 뭉쳐져 있다고 판단하여 해당 칼럼을 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eaac955",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.727072Z",
          "start_time": "2022-07-04T14:19:58.673958Z"
        },
        "id": "0eaac955",
        "outputId": "3b84b353-ae41-4b91-f5df-89f1b6770a70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2583: UserWarning: n_quantiles (1000) is greater than the total number of samples (365). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 8등 코드\n",
        "scaler1 = QuantileTransformer()\n",
        "scaler2 = QuantileTransformer()\n",
        "col___list = ['PM10','PM2.5','sunshine_rate','sunshine_sum', 'precipitation']\n",
        "scaler1.fit(train_[col___list])\n",
        "X_train_scaled = scaler1.transform(train_[col___list])\n",
        "train_[col___list] =X_train_scaled\n",
        "scaler2.fit(test_df[col___list])\n",
        "X_train_scaled = scaler2.transform(test_df[col___list])\n",
        "test_df[col___list] =X_train_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5d87a1",
      "metadata": {
        "id": "6c5d87a1"
      },
      "source": [
        "# feature 추가 (train & test)\n",
        "> correlation 을 통해 데이터를 보았을때, rental 과 상관관계가 제일 높은 feature 를 선택 후 조합하여 추가 feature 생성\n",
        ">> dust = pm10 * pm2.5 & abs(일교차) & sunshine_rate/sunshine_sum & sunshine_sum 에 있는 결측값 채우기\n",
        ">>\n",
        ">> test 데이터의 경우 미세먼지를 통해 만든 신호등에서 4번케이스가 없기에 0으로 채워둠. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b0c672c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.773323Z",
          "start_time": "2022-07-04T14:19:58.738108Z"
        },
        "id": "9b0c672c"
      },
      "outputs": [],
      "source": [
        "train_ = pd.get_dummies(data = train_,columns = ['pm'])\n",
        "train_['PMs'] = train_['PM10'] * train_['PM2.5']\n",
        "train_['absolute_diff'] = abs(train_['temp_highest'] - train_['temp_lowest'])\n",
        "train_['rate/sum'] = train_['sunshine_rate'] / train_['sunshine_sum']\n",
        "train_['rate/sum'] = train_['rate/sum'].fillna(method='bfill')\n",
        "\n",
        "\n",
        "test_df = pd.get_dummies(data = test_df,columns = ['pm'])\n",
        "test_df['pm_4']=0.0\n",
        "test_df['pm_4']=test_df['pm_4'].astype('uint8')\n",
        "test_df['PMs'] = test_df['PM10'] * test_df['PM2.5']\n",
        "test_df['absolute_diff'] = abs(test_df['temp_highest'] - test_df['temp_lowest'])\n",
        "test_df['rate/sum'] = test_df['sunshine_rate'] / test_df['sunshine_sum']\n",
        "test_df['rate/sum'] = test_df['rate/sum'].fillna(method='bfill')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b6016e2",
      "metadata": {
        "id": "2b6016e2"
      },
      "source": [
        "# feature drop\n",
        "> 불필요하다고 판단한 sunshine_sum을 train, test 데이터에서 drop \n",
        ">> rental-sunshine_sum 데이터 Plot을 보면, rate 을 통해서 진행하는 것이 더 유의미하다고 판단. (실제로 성능차이가 sum 을 제외한 것이 더 좋았음 rate 을 제거한 것보다)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da898a30",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.797000Z",
          "start_time": "2022-07-04T14:19:58.776748Z"
        },
        "id": "da898a30"
      },
      "outputs": [],
      "source": [
        "train_=train_.drop(columns='sunshine_sum')\n",
        "test_df=test_df.drop(columns='sunshine_sum')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696f0e96",
      "metadata": {
        "id": "696f0e96"
      },
      "source": [
        "# train, test 데이터 확인\n",
        "> 사전에 진행한 전처리 과정이 제대로 되었는지 .info() 를 통해 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4175e4df",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:19:58.842950Z",
          "start_time": "2022-07-04T14:19:58.802631Z"
        },
        "id": "4175e4df",
        "outputId": "aa6ef207-9dac-49a6-d399-88b7f62686b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1095 entries, 0 to 1094\n",
            "Data columns (total 32 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   precipitation       1095 non-null   float64\n",
            " 1   temp_mean           1095 non-null   float64\n",
            " 2   temp_highest        1095 non-null   float64\n",
            " 3   temp_lowest         1095 non-null   float64\n",
            " 4   temp_sensible       1095 non-null   float64\n",
            " 5   temp_diff           1095 non-null   float64\n",
            " 6   PM10                1095 non-null   float64\n",
            " 7   PM2.5               1095 non-null   float64\n",
            " 8   humidity            1095 non-null   float64\n",
            " 9   sunshine_rate       1095 non-null   float64\n",
            " 10  wind_mean           1095 non-null   float64\n",
            " 11  wind_max            1095 non-null   float64\n",
            " 12  rental              1095 non-null   float64\n",
            " 13  holiday             1095 non-null   int64  \n",
            " 14  year                1095 non-null   int64  \n",
            " 15  month               1095 non-null   int64  \n",
            " 16  day                 1095 non-null   int64  \n",
            " 17  day_name_Friday     1095 non-null   uint8  \n",
            " 18  day_name_Monday     1095 non-null   uint8  \n",
            " 19  day_name_Saturday   1095 non-null   uint8  \n",
            " 20  day_name_Sunday     1095 non-null   uint8  \n",
            " 21  day_name_Thursday   1095 non-null   uint8  \n",
            " 22  day_name_Tuesday    1095 non-null   uint8  \n",
            " 23  day_name_Wednesday  1095 non-null   uint8  \n",
            " 24  discomfort_index    1095 non-null   float64\n",
            " 25  pm_1                1095 non-null   uint8  \n",
            " 26  pm_2                1095 non-null   uint8  \n",
            " 27  pm_3                1095 non-null   uint8  \n",
            " 28  pm_4                1095 non-null   uint8  \n",
            " 29  PMs                 1095 non-null   float64\n",
            " 30  absolute_diff       1095 non-null   float64\n",
            " 31  rate/sum            1095 non-null   float64\n",
            "dtypes: float64(17), int64(4), uint8(11)\n",
            "memory usage: 191.5 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 365 entries, 0 to 364\n",
            "Data columns (total 31 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   precipitation       365 non-null    float64\n",
            " 1   temp_mean           365 non-null    float64\n",
            " 2   temp_highest        365 non-null    float64\n",
            " 3   temp_lowest         365 non-null    float64\n",
            " 4   temp_sensible       365 non-null    float64\n",
            " 5   temp_diff           365 non-null    float64\n",
            " 6   PM10                365 non-null    float64\n",
            " 7   PM2.5               365 non-null    float64\n",
            " 8   humidity            365 non-null    float64\n",
            " 9   sunshine_rate       365 non-null    float64\n",
            " 10  wind_mean           365 non-null    float64\n",
            " 11  wind_max            365 non-null    float64\n",
            " 12  holiday             0 non-null      float64\n",
            " 13  year                365 non-null    int64  \n",
            " 14  month               365 non-null    int64  \n",
            " 15  day                 365 non-null    int64  \n",
            " 16  day_name_Friday     365 non-null    uint8  \n",
            " 17  day_name_Monday     365 non-null    uint8  \n",
            " 18  day_name_Saturday   365 non-null    uint8  \n",
            " 19  day_name_Sunday     365 non-null    uint8  \n",
            " 20  day_name_Thursday   365 non-null    uint8  \n",
            " 21  day_name_Tuesday    365 non-null    uint8  \n",
            " 22  day_name_Wednesday  365 non-null    uint8  \n",
            " 23  discomfort_index    365 non-null    float64\n",
            " 24  pm_1                365 non-null    uint8  \n",
            " 25  pm_2                365 non-null    uint8  \n",
            " 26  pm_3                365 non-null    uint8  \n",
            " 27  pm_4                365 non-null    uint8  \n",
            " 28  PMs                 365 non-null    float64\n",
            " 29  absolute_diff       365 non-null    float64\n",
            " 30  rate/sum            365 non-null    float64\n",
            "dtypes: float64(17), int64(3), uint8(11)\n",
            "memory usage: 61.1 KB\n"
          ]
        }
      ],
      "source": [
        "train_.info()\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2e1395",
      "metadata": {
        "id": "8b2e1395"
      },
      "source": [
        "# 모델 선택 후 예측\n",
        "> 모델은 kaggle 에서 제일 많은 우승을 들고 가고 있는 xgboost 를 선택."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c456d7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:20:02.543384Z",
          "start_time": "2022-07-04T14:19:58.849205Z"
        },
        "id": "22c456d7"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBRegressor as model\n",
        "\n",
        "y = train_['rental']\n",
        "x= train_.drop('rental',axis =1)\n",
        "model = XGBRegressor(objective='reg:squarederror',learning_rate=0.1,max_depth = 4, n_estimators = 1000)\n",
        "model.fit(x, y)\n",
        "pred = model.predict(test_df)      \n",
        "pred = pd.DataFrame(pred, columns=['rental'])\n",
        "pred = np.expm1(pred)*1.35"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c448f861",
      "metadata": {
        "id": "c448f861"
      },
      "source": [
        "# 결과 도출\n",
        "> submission 코드, rental 에 예측한 prediction 값 넣기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066cfb94",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:20:02.704525Z",
          "start_time": "2022-07-04T14:20:02.643015Z"
        },
        "id": "066cfb94",
        "outputId": "fc490cbc-32cb-4af2-9ef8-5fc7ee26a1b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>rental</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>27550.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-02</td>\n",
              "      <td>26879.683594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-03</td>\n",
              "      <td>17775.929688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>33266.390625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-05</td>\n",
              "      <td>26452.082031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>2021-12-27</td>\n",
              "      <td>34484.773438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>2021-12-28</td>\n",
              "      <td>37353.417969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>2021-12-29</td>\n",
              "      <td>46339.921875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>2021-12-30</td>\n",
              "      <td>35921.660156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>2021-12-31</td>\n",
              "      <td>37187.707031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date        rental\n",
              "0    2021-01-01  27550.500000\n",
              "1    2021-01-02  26879.683594\n",
              "2    2021-01-03  17775.929688\n",
              "3    2021-01-04  33266.390625\n",
              "4    2021-01-05  26452.082031\n",
              "..          ...           ...\n",
              "360  2021-12-27  34484.773438\n",
              "361  2021-12-28  37353.417969\n",
              "362  2021-12-29  46339.921875\n",
              "363  2021-12-30  35921.660156\n",
              "364  2021-12-31  37187.707031\n",
              "\n",
              "[365 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['rental'] = pred\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44d1cdde",
      "metadata": {
        "id": "44d1cdde"
      },
      "source": [
        "# to_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8707546",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-04T14:20:02.722313Z",
          "start_time": "2022-07-04T14:20:02.711518Z"
        },
        "id": "e8707546"
      },
      "outputs": [],
      "source": [
        "sample.to_csv('7.02result2.csv',index=False, encoding = 'UTF-8')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "정리_완료_코드제출_v1.0_220704.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}